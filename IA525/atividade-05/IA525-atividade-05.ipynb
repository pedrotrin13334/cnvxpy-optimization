{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\"\"\" \n",
    "Código para ler o csv do dataset \n",
    "\"\"\"\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "\n",
    "iris_data = pd.read_csv('iris.data', header=None, names=column_names)\n",
    "\n",
    "print(iris_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 1:** Considerando cada uma das duas técnicas descritas acima, encontre três classificadores binários, cada um\n",
    "classificando uma espécie contra as outras duas (logo, você fará seis classificadores no total, três por QM e outros\n",
    "três por SVM). Forneça a taxa de erro de cada um destes classificadores, tanto no conjunto de treinamento quanto\n",
    "no conjunto de teste.\n",
    "\n",
    "**Resposta:** Segue o código de implementação do classificador linear implementado com Mínimo Quadrados e também utilizando a estratégia do SVM. Os erros para cada caso estão sendo printados em códigos posteriores abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def linear_least_squares_classifier(df, target_class):\n",
    "    # Vamos preparar os dados com features e labels\n",
    "    X = df.iloc[:, :-1].values  # Pegamos todas as colunas menos a última\n",
    "    y = np.where(df['class'] == target_class, 1, -1)  # 1 para a classe de interesse, -1 do contrário\n",
    "    \n",
    "    # número de features no dataset \n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # Vamos resolver o problema com o cvxpy\n",
    "    a = cp.Variable(n_features)  # Vetor de pesos\n",
    "    b = cp.Variable()           # termo de bias\n",
    "    \n",
    "    # Aqui é a definição dos mínimos quadrados\n",
    "    objective = cp.Minimize(cp.sum_squares(X @ a + b - y))\n",
    "    problem = cp.Problem(objective)\n",
    "    \n",
    "    # Então resolvemos o problema\n",
    "    problem.solve()\n",
    "    \n",
    "    return a.value, b.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights (a): [ 0.1312861   0.48494601 -0.44552275 -0.12670283]\n",
      "Bias (b): -0.7550609184556691\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Apenas um código demonstrando o treinamento e pesos sendo gerados\n",
    "\"\"\"\n",
    "iris_data = pd.read_csv('iris.data', header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'])\n",
    "a, b = linear_least_squares_classifier(iris_data, 'Iris-setosa')\n",
    "\n",
    "print(\"Weights (a):\", a)\n",
    "print(\"Bias (b):\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Código utilitário para ajudar a separar teste/validação\n",
    "    e calcular o erro\n",
    "\"\"\"\n",
    "def train_test_split_pandas(df, test_size=0.2, random_state=11):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Vamos embaralhar o dataset\n",
    "    df_shuffled = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    # Separa em treino / validação\n",
    "    n = len(df_shuffled)\n",
    "    n_val = int(n * test_size)\n",
    "    \n",
    "    df_val = df_shuffled.iloc[:n_val]\n",
    "    df_train = df_shuffled.iloc[n_val:]\n",
    "    \n",
    "    return df_train, df_val\n",
    "\n",
    "def calculate_classification_error(y_true, y_pred):\n",
    "    return np.mean(y_true != y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QM Para o tipo Iris-setosa\n",
      "Erro de validação para conjunto de treinamento Iris-setosa: 0.00%\n",
      "Erro de validação para conjunto de teste Iris-setosa: 0.00%\n",
      "\n",
      "QM Para o tipo Iris-versicolor\n",
      "Erro de validação para conjunto de treinamento Iris-versicolor: 24.00%\n",
      "Erro de validação para conjunto de teste Iris-versicolor: 30.00%\n",
      "\n",
      "QM Para o tipo Iris-virginica\n",
      "Erro de validação para conjunto de treinamento Iris-virginica: 6.00%\n",
      "Erro de validação para conjunto de teste Iris-virginica: 10.00%\n"
     ]
    }
   ],
   "source": [
    "iris_types = ['Iris-setosa','Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "iris_data = pd.read_csv('iris.data', header=None, \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])\n",
    "\n",
    "df_train, df_val = train_test_split_pandas(iris_data, test_size=1/3)\n",
    "\n",
    "for iris_type in iris_types:\n",
    "       print(f\"\\nQM Para o tipo {iris_type}\")\n",
    "       a, b = linear_least_squares_classifier(df_train, target_class=iris_type)\n",
    "\n",
    "       X_train = df_train.iloc[:, :-1].values\n",
    "       y_train_true = np.where(df_train['class'] == iris_type, 1, -1)\n",
    "\n",
    "       # Aqui é a predição do modelo para o conjunto de treino\n",
    "       y_train_pred = np.sign(X_train @ a + b)\n",
    "       error = calculate_classification_error(y_train_true, y_train_pred)\n",
    "       print(f\"Erro de validação para conjunto de treinamento {iris_type}: {error:.2f}%\")\n",
    "\n",
    "       X_val = df_val.iloc[:, :-1].values\n",
    "       y_val_true = np.where(df_val['class'] == iris_type, 1, -1)\n",
    "\n",
    "       # Aqui é a predição do modelo para o conjunto de teste\n",
    "       y_val_pred = np.sign(X_val @ a + b)\n",
    "\n",
    "       error = calculate_classification_error(y_val_true, y_val_pred)\n",
    "       print(f\"Erro de validação para conjunto de teste {iris_type}: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(df, target_class):\n",
    "    # Basicamente o mesmo processo do classificador anterior\n",
    "    X = df.iloc[:, :-1].values  \n",
    "    y = np.where(df['class'] == target_class, 1, -1)  \n",
    "    \n",
    "    _, n_features = X.shape\n",
    "    \n",
    "    a = cp.Variable(n_features)  \n",
    "    b = cp.Variable()            \n",
    "    \n",
    "    # aqui a gente muda a função objetivo em relação ao classificador anterior\n",
    "    hinge_loss = cp.sum(cp.pos(1 - cp.multiply(y, X @ a + b)))\n",
    "    \n",
    "    problem = cp.Problem(cp.Minimize(hinge_loss))\n",
    "    problem.solve()\n",
    "    \n",
    "    return a.value, b.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Para o tipo Iris-setosa\n",
      "Erro de validação para conjunto de treinamento Iris-setosa: 0.00%\n",
      "Erro de validação para conjunto de teste Iris-setosa: 0.00%\n",
      "\n",
      "SVM Para o tipo Iris-versicolor\n",
      "Erro de validação para conjunto de treinamento Iris-versicolor: 24.00%\n",
      "Erro de validação para conjunto de teste Iris-versicolor: 32.00%\n",
      "\n",
      "SVM Para o tipo Iris-virginica\n",
      "Erro de validação para conjunto de treinamento Iris-virginica: 2.00%\n",
      "Erro de validação para conjunto de teste Iris-virginica: 4.00%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Código que printa os erros para o classificador SVM\n",
    "\"\"\"\n",
    "iris_types = ['Iris-setosa','Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "iris_data = pd.read_csv('iris.data', header=None, \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])\n",
    "\n",
    "df_train, df_val = train_test_split_pandas(iris_data, test_size=1/3)\n",
    "\n",
    "for iris_type in iris_types:\n",
    "       print(f\"\\nSVM Para o tipo {iris_type}\")\n",
    "       a, b = svm_classifier(df_train, target_class=iris_type)\n",
    "\n",
    "       X_train = df_train.iloc[:, :-1].values\n",
    "       y_train_true = np.where(df_train['class'] == iris_type, 1, -1)\n",
    "\n",
    "       y_train_pred = np.sign(X_train @ a + b)\n",
    "       error = calculate_classification_error(y_train_true, y_train_pred)\n",
    "       print(f\"Erro de validação para conjunto de treinamento {iris_type}: {error:.2f}%\")\n",
    "\n",
    "       X_val = df_val.iloc[:, :-1].values\n",
    "       y_val_true = np.where(df_val['class'] == iris_type, 1, -1)\n",
    "\n",
    "       y_val_pred = np.sign(X_val @ a + b)\n",
    "\n",
    "       error = calculate_classification_error(y_val_true, y_val_pred)\n",
    "       print(f\"Erro de validação para conjunto de teste {iris_type}: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 2:** Combine os classificadores desenvolvidos acima para obter dois classificadores de 3 classes, um desenvol-\n",
    "vido por quadrados mı́nimos e o segundo por otimizaçao linear, e forneça a matriz de confusão para os conjuntos\n",
    "de treinamento e de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_multiclass_classifier(df):\n",
    "    classes = df['class'].unique() # Lista de classes únicas\n",
    "    classifiers = {}\n",
    "    \n",
    "    for target_class in classes:\n",
    "        # Treino de um classificador linear para cada classe\n",
    "        a, b = linear_least_squares_classifier(df, target_class)\n",
    "        classifiers[target_class] = (a, b)\n",
    "    \n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiclass(X, classifiers):\n",
    "    scores = {}\n",
    "    for class_name, (a, b) in classifiers.items():\n",
    "        scores[class_name] = X @ a + b  # Score de decisão para cada classe\n",
    "    \n",
    "    # seleciona a classe com maior score\n",
    "    return np.array([max(scores, key=lambda k: scores[k][i]) for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_multiclass_classifier(df):\n",
    "    classes = df['class'].unique()  \n",
    "    classifiers = {}\n",
    "    \n",
    "    for target_class in classes:\n",
    "        a, b = svm_classifier(df, target_class)\n",
    "        classifiers[target_class] = (a, b)\n",
    "    \n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro de validação para o QM: 20.00%\n",
      "Erro de validação para o SVM: 4.00%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Código para simples teste do erro de validação para o SVM \n",
    "   e QM linear multiclasse.\n",
    "\"\"\"\n",
    "iris_data = pd.read_csv('iris.data', header=None, \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])\n",
    "df_train, df_val = train_test_split_pandas(iris_data, test_size=1/3, random_state=42)\n",
    "\n",
    "classifiers = train_linear_multiclass_classifier(df_train)\n",
    "\n",
    "X_val = df_val.iloc[:, :-1].values\n",
    "y_val_pred = predict_multiclass(X_val, classifiers)\n",
    "\n",
    "y_val_true = df_val['class'].values\n",
    "error = calculate_classification_error(y_val_true, y_val_pred)\n",
    "print(f\"Erro de validação para o QM: {error:.2f}%\")\n",
    "\n",
    "classifiers = train_svm_multiclass_classifier(df_train)\n",
    "y_val_pred = predict_multiclass(X_val, classifiers)\n",
    "\n",
    "error = calculate_classification_error(y_val_true, y_val_pred)\n",
    "print(f\"Erro de validação para o SVM: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para computar a matriz de confusão\n",
    "def compute_confusion_matrix(classifiers, df_val):\n",
    "    X_val = df_val.iloc[:, :-1].values\n",
    "    y_true = df_val['class'].values\n",
    "    y_pred = predict_multiclass(X_val, classifiers)\n",
    "    \n",
    "    classes = sorted(np.unique(y_true))\n",
    "    cm = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "    \n",
    "    for i, true_class in enumerate(classes):\n",
    "        for j, pred_class in enumerate(classes):\n",
    "            cm[i, j] = np.sum((y_true == true_class) & (y_pred == pred_class))\n",
    "    \n",
    "    return pd.DataFrame(cm, index=classes, columns=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão para o dataset de treino do QM:\n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               35                0               0\n",
      "Iris-versicolor            0               20              11\n",
      "Iris-virginica             0                2              32\n",
      "Matriz de confusão para o dataset de validação do QM:\n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               14                1               0\n",
      "Iris-versicolor            0                9              10\n",
      "Iris-virginica             0                1              15\n",
      "\n",
      "------------------------------------------------------------\n",
      "Matriz de confusão para o dataset de treino do SVM:\n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               35                0               0\n",
      "Iris-versicolor            0               29               2\n",
      "Iris-virginica             0                2              32\n",
      "Matriz de confusão para o dataset de validação do SVM:\n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               14                1               0\n",
      "Iris-versicolor            2               15               2\n",
      "Iris-virginica             0                0              16\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "   Código para calcular matriz de confusão do QM e do SVM\n",
    "\"\"\"\n",
    "iris_data = pd.read_csv('iris.data', header=None, \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])\n",
    "\n",
    "df_train, df_val = train_test_split_pandas(iris_data, test_size=1/3)\n",
    "\n",
    "classifiers = train_linear_multiclass_classifier(df_train)\n",
    "\n",
    "cm = compute_confusion_matrix(classifiers, df_train)\n",
    "print(\"Matriz de confusão para o dataset de treino do QM:\")\n",
    "print(cm)\n",
    "cm = compute_confusion_matrix(classifiers, df_val)\n",
    "print(\"Matriz de confusão para o dataset de validação do QM:\")\n",
    "print(cm)\n",
    "\n",
    "classifiers = train_svm_multiclass_classifier(df_train)\n",
    "print(\"\\n------------------------------------------------------------\")\n",
    "cm = compute_confusion_matrix(classifiers, df_train)\n",
    "print(\"Matriz de confusão para o dataset de treino do SVM:\")\n",
    "print(cm)\n",
    "cm = compute_confusion_matrix(classifiers, df_val)\n",
    "print(\"Matriz de confusão para o dataset de validação do SVM:\")\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questão 3:** Compare os resultados obtidos nos itens anteriores. Qual classificador apresentou melhor desempenho, em\n",
    "geral?\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "Notamos pelos experimentos que a performance geral do classificador multiclasse com SVM foi melhor do que o multiclasse com o QM, o que é um resultado interessante, dado que individualmente a taxa de erro dos dois tipos de classificadores foram próximas.\n",
    "\n",
    " Mas o SVM nesse contexto se mostrou melhor em separar as Iris do tipo Iris-virginica, melhorando a fronteira de decisão, diminuindo o erro de classificação entre Iris-versicolor e Iris-virginica, por exemplo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optmization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
