{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define column names (since iris.data typically has no headers)\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "\n",
    "# Read the CSV file\n",
    "iris_data = pd.read_csv('iris.data', header=None, names=column_names)\n",
    "\n",
    "# Display the first few rows\n",
    "print(iris_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def linear_least_squares_classifier(df, target_class):\n",
    "    # Prepare data: Features (X) and binary labels (y)\n",
    "    X = df.iloc[:, :-1].values  # All columns except the last\n",
    "    y = np.where(df['class'] == target_class, 1, -1)  # 1 for target class, -1 otherwise\n",
    "    \n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # Define optimization variables\n",
    "    a = cp.Variable(n_features)  # Weight vector\n",
    "    b = cp.Variable()           # Bias term\n",
    "    \n",
    "    # Define the least squares problem\n",
    "    objective = cp.Minimize(cp.sum_squares(X @ a + b - y))\n",
    "    problem = cp.Problem(objective)\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem.solve()\n",
    "    \n",
    "    return a.value, b.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights (a): [ 0.1312861   0.48494601 -0.44552275 -0.12670283]\n",
      "Bias (b): -0.7550609184556691\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Load the Iris dataset (assuming iris_data is loaded as before)\n",
    "iris_data = pd.read_csv('iris.data', header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'])\n",
    "\n",
    "# Fit a linear classifier for 'Iris-setosa'\n",
    "a, b = linear_least_squares_classifier(iris_data, 'Iris-setosa')\n",
    "\n",
    "print(\"Weights (a):\", a)\n",
    "print(\"Bias (b):\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test_split_pandas(df, test_size=0.2, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    # Shuffle the DataFrame\n",
    "    df_shuffled = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    # Split into train/validation\n",
    "    n = len(df_shuffled)\n",
    "    n_val = int(n * test_size)\n",
    "    \n",
    "    df_val = df_shuffled.iloc[:n_val]\n",
    "    df_train = df_shuffled.iloc[n_val:]\n",
    "    \n",
    "    return df_train, df_val\n",
    "\n",
    "def calculate_classification_error(y_true, y_pred):\n",
    "    return np.mean(y_true != y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "iris_data = pd.read_csv('iris.data', header=None, \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])\n",
    "\n",
    "# Split into train/validation \n",
    "df_train, df_val = train_test_split_pandas(iris_data, test_size=1/3)\n",
    "\n",
    "# Train linear classifier (using your CVXPY function)\n",
    "a, b = linear_least_squares_classifier(df_train, target_class='Iris-setosa')\n",
    "\n",
    "# Prepare validation data\n",
    "X_val = df_val.iloc[:, :-1].values\n",
    "y_val_true = np.where(df_val['class'] == 'Iris-setosa', 1, -1)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = np.sign(X_val @ a + b)\n",
    "\n",
    "# Calculate error\n",
    "error = calculate_classification_error(y_val_true, y_val_pred)\n",
    "print(f\"Validation Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_multiclass_classifier(df):\n",
    "    classes = df['class'].unique()  # List of unique classes\n",
    "    classifiers = {}\n",
    "    \n",
    "    for target_class in classes:\n",
    "        # Train a binary classifier for each class\n",
    "        a, b = linear_least_squares_classifier(df, target_class)\n",
    "        classifiers[target_class] = (a, b)\n",
    "    \n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_hinge_loss_classifier(df, target_class):\n",
    "   \n",
    "    # Prepare data\n",
    "    X = df.iloc[:, :-1].values  # Features\n",
    "    y = np.where(df['class'] == target_class, 1, -1)  # Binary labels\n",
    "    \n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Define variables\n",
    "    a = cp.Variable(n_features)  # Weight vector\n",
    "    b = cp.Variable()            # Bias term\n",
    "    \n",
    "    # Hinge loss: sum(max(0, 1 - y_i*(a^T x_i + b)))\n",
    "    hinge_loss = cp.sum(cp.pos(1 - cp.multiply(y, X @ a + b)))\n",
    "    \n",
    "    # Solve the problem (no regularization)\n",
    "    problem = cp.Problem(cp.Minimize(hinge_loss))\n",
    "    problem.solve()\n",
    "    \n",
    "    return a.value, b.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiclass(X, classifiers):\n",
    "    scores = {}\n",
    "    for class_name, (a, b) in classifiers.items():\n",
    "        scores[class_name] = X @ a + b  # Decision score for each class\n",
    "    \n",
    "    # Select the class with the highest score\n",
    "    return np.array([max(scores, key=lambda k: scores[k][i]) for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_multiclass_classifier(df):\n",
    "    classes = df['class'].unique()  # List of unique classes\n",
    "    classifiers = {}\n",
    "    \n",
    "    for target_class in classes:\n",
    "        # Train a binary classifier for each class\n",
    "        a, b = svm_hinge_loss_classifier(df, target_class)\n",
    "        classifiers[target_class] = (a, b)\n",
    "    \n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error: 13.33%\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and split the Iris dataset\n",
    "iris_data = pd.read_csv('iris.data', header=None, \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])\n",
    "df_train, df_val = train_test_split_pandas(iris_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Train the multi-class classifier\n",
    "classifiers = train_linear_multiclass_classifier(df_train)\n",
    "\n",
    "# 3. Predict on validation data\n",
    "X_val = df_val.iloc[:, :-1].values\n",
    "y_val_pred = predict_multiclass(X_val, classifiers)\n",
    "\n",
    "# 4. Calculate error\n",
    "y_val_true = df_val['class'].values\n",
    "error = calculate_classification_error(y_val_true, y_val_pred)\n",
    "print(f\"Validation Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "iris_data = pd.read_csv('iris.data', header=None, \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])\n",
    "\n",
    "# Split into train/validation \n",
    "df_train, df_val = train_test_split_pandas(iris_data, test_size=1/3)\n",
    "\n",
    "# Train linear classifier (using your CVXPY function)\n",
    "a, b = svm_hinge_loss_classifier(df_train, target_class='Iris-setosa')\n",
    "\n",
    "# Prepare validation data\n",
    "X_val = df_val.iloc[:, :-1].values\n",
    "y_val_true = np.where(df_val['class'] == 'Iris-setosa', 1, -1)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = np.sign(X_val @ a + b)\n",
    "\n",
    "# Calculate error\n",
    "error = calculate_classification_error(y_val_true, y_val_pred)\n",
    "print(f\"Validation Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and split the Iris dataset\n",
    "iris_data = pd.read_csv('iris.data', header=None, \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])\n",
    "df_train, df_val = train_test_split_pandas(iris_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Train the multi-class classifier\n",
    "classifiers = train_svm_multiclass_classifier(df_train)\n",
    "\n",
    "# 3. Predict on validation data\n",
    "X_val = df_val.iloc[:, :-1].values\n",
    "y_val_pred = predict_multiclass(X_val, classifiers)\n",
    "\n",
    "# 4. Calculate error\n",
    "y_val_true = df_val['class'].values\n",
    "error = calculate_classification_error(y_val_true, y_val_pred)\n",
    "print(f\"Validation Error: {error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(classifiers, df_val):\n",
    "    X_val = df_val.iloc[:, :-1].values\n",
    "    y_true = df_val['class'].values\n",
    "    y_pred = predict_multiclass(X_val, classifiers)\n",
    "    \n",
    "    classes = sorted(np.unique(y_true))\n",
    "    cm = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "    \n",
    "    for i, true_class in enumerate(classes):\n",
    "        for j, pred_class in enumerate(classes):\n",
    "            cm[i, j] = np.sum((y_true == true_class) & (y_pred == pred_class))\n",
    "    \n",
    "    return pd.DataFrame(cm, index=classes, columns=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                 Iris-setosa  Iris-versicolor  Iris-virginica\n",
      "Iris-setosa               19                0               0\n",
      "Iris-versicolor            0                7               8\n",
      "Iris-virginica             0                2              14\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "iris_data = pd.read_csv('iris.data', header=None, \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])\n",
    "\n",
    "# Split data\n",
    "df_train, df_val = train_test_split_pandas(iris_data, test_size=1/3)\n",
    "\n",
    "# Train multi-class SVM\n",
    "classifiers = train_linear_multiclass_classifier(df_train)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = compute_confusion_matrix(classifiers, df_val)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optmization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
